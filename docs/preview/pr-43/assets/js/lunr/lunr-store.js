var store = [{
        "title": "言語の表現空間の形, 数理科学 2025年10月号 No.748「データの幾何学と機械学習-データの「近さ」や「繋がり」を捉える-」",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/books/202510-article-mathscience/",
        "teaser": null
      },{
        "title": "確率的機械学習：入門編 I ―基礎と線形モデル―",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/books/202511-book-Murphy1/",
        "teaser": null
      },{
        "title": "確率的機械学習：入門編 II ―非線形モデル―",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/books/202511-book-murphy2/",
        "teaser": null
      },{
        "title": "不均衡最適輸送を用いた意味変化検出",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/domesticConferences/202503-nlp-kishino/",
        "teaser": null
      },{
        "title": "層の冗長性と層同士の独立性に基づく言語モデルの層交換の成否の特徴づけ",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/domesticConferences/202503-nlp-kobayashi/",
        "teaser": null
      },{
        "title": "文長による内容語率の変化が引き起こす文ベクトルの品質低下",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/domesticConferences/202505-jsai-hara/",
        "teaser": null
      },{
        "title": "密度比の直接推定に基づく言語モデルの出力較正",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/domesticConferences/202509-yans-kamoda/",
        "teaser": null
      },{
        "title": "拡散言語モデルによる日本語縦読み文章生成",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/domesticConferences/202509-yans-kazama/",
        "teaser": null
      },{
        "title": "なぜ一次モーメント情報のみ残したテキスト埋め込みはうまく動くのか？：単語埋め込み集合における二次モーメント情報の崩壊の分析",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/domesticConferences/202511-ibis-hara/",
        "teaser": null
      },{
        "title": "言語モデルの最終隠れ状態のソフト分割可能な単体複体としての分析",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/domesticConferences/202511-ibis-ishimine/",
        "teaser": null
      },{
        "title": "p進数を用いた単語埋め込みについて",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/domesticConferences/202511-ibis-mihara/",
        "teaser": null
      },{
        "title": "なぜ平均プーリングはうまく動くのか？テキスト埋め込みの二次統計量の崩壊の定量化",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/domesticConferences/202603-nlp-hara/",
        "teaser": null
      },{
        "title": "単体複体を用いた次単語予測分布の幾何的解釈",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/domesticConferences/202603-nlp-ishimine/",
        "teaser": null
      },{
        "title": "Attention Sink および Massive Activation の発生機序の分解",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/domesticConferences/202603-nlp-kiya/",
        "teaser": null
      },{
        "title": "タスク算術の誤差項とその解釈",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/domesticConferences/202603-nlp-lee/",
        "teaser": null
      },{
        "title": "注意機構における Attention Sink のバイアス項的解釈",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/domesticConferences/202603-nlp-ohashi/",
        "teaser": null
      },{
        "title": "言語モデルに線形に内在する階層的概念",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/domesticConferences/202603-nlp-sakata/",
        "teaser": null
      },{
        "title": "Mambaの\"処理時間\"はヒトの読み時間と符号する",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/domesticConferences/202603-nlp-yamamoto/",
        "teaser": null
      },{
        "title": "SoftMatcha 2: 一兆語規模のコーパスに対する柔らかく超高速な検索システム",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/domesticConferences/202603-nlp-yoneda/",
        "teaser": null
      },{
        "title": "SoftMatcha: A Soft and Fast Pattern Matcher for Billion-Scale Corpus Searches",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/internationalConferences/202504-iclr-deguchi/",
        "teaser": null
      },{
        "title": "TAID: Temporally Adaptive Interpolated Distillation for Efficient Knowledge Transfer in Language Models",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/internationalConferences/202504-iclr-shing/",
        "teaser": null
      },{
        "title": "On Entity Identification in Language Models",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/internationalConferences/202507-acl-sakata/",
        "teaser": null
      },{
        "title": "Understanding the Side Effects of Rank-One Knowledge Editing",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/internationalConferences/202511-blackboxnlp-takahashi/",
        "teaser": null
      },{
        "title": "How a Bilingual LM Becomes Bilingual: Tracing Internal Representations with Sparse Autoencoders",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/internationalConferences/202511-emnlp-inaba/",
        "teaser": null
      },{
        "title": "Can Language Models Handle a Non-Gregorian Calendar?",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/internationalConferences/202512-aacl-sasaki/",
        "teaser": null
      },{
        "title": "言語モデルの内部機序：解析と解釈",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/invitedTalks/202503-nlp2025-tutorial/",
        "teaser": null
      },{
        "title": "「確率的なオウム」にできること，またそれがなぜできるのかについて",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/invitedTalks/202509-yokoi-JAECS/",
        "teaser": null
      },{
        "title": "Go_kamoda",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/members/go_kamoda/",
        "teaser": null
      },{
        "title": "Hikaru_nakao",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/members/hikaru_nakao/",
        "teaser": null
      },{
        "title": "Kai_nakaishi",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/members/kai_nakaishi/",
        "teaser": null
      },{
        "title": "Masahiro_kazama",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/members/masahiro_kazama/",
        "teaser": null
      },{
        "title": "Ryo_ueda",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/members/ryo_ueda/",
        "teaser": null
      },{
        "title": "Saori_morita",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/members/saori_morita/",
        "teaser": null
      },{
        "title": "Sho_yokoi",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/members/sho_yokoi/",
        "teaser": null
      },{
        "title": "Shuri_kozuka",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/members/shuri_kozuka/",
        "teaser": null
      },{
        "title": "Takumi_ishimine",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/members/takumi_ishimine/",
        "teaser": null
      },{
        "title": "Yuji_yamamoto",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/preview/pr-43/members/yuji_yamamoto/",
        "teaser": null
      },{
        "title": "研究室のウェブサイトが立ち上がりました",
        "excerpt":"2025年4月に始動した横井研究室 @ 国語研のウェブサイトが立ち上がりました．  立ち上げに際して発生した技術的問題については，博士課程の鴨田さん・山本さんがそのほとんどをさらりと解決してくださいました，ありがとうございます！（横井）  ","categories": ["Blog"],
        "tags": [],
        "url": "/preview/pr-43/posts/website-launch/",
        "teaser": null
      },{
        "title": "NLP2026ではN件の発表があります",
        "excerpt":"ここに文章 原知正, 栗田宙人, 今泉允聡, 乾健太郎, 横井祥. なぜ平均プーリングはうまく動くのか？テキスト埋め込みの二次統計量の崩壊の定量化. ポスター発表, 言語処理学会第32回年次大会 (NLP 2026). 宇都宮, 2026年3月. 石峯拓海, 日野英逸, 横井祥. 単体複体を用いた次単語予測分布の幾何的解釈. ポスター発表, 言語処理学会第32回年次大会 (NLP 2026). 宇都宮, 2026年3月. 木谷頼斗, 大橋諭貴, 佐藤宏亮, 鴨田豪, 高橋良允, 山本悠士, 塩野大輝, 坂口慶祐, 小林悟郎. Attention Sink および Massive Activation の発生機序の分解. ポスター発表, 言語処理学会第32回年次大会 (NLP 2026). 宇都宮, 2026年3月. 李宰成, 中石海, 横井祥. タスク算術の誤差項とその解釈. ポスター発表, 言語処理学会第32回年次大会...","categories": ["Blog"],
        "tags": [],
        "url": "/preview/pr-43/posts/nlp2026-publications/",
        "teaser": null
      }]
